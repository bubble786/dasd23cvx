#!/usr/bin/env python3
"""
æ‰“å°è¾“å‡ºbasePCFGçš„grammarç»Ÿè®¡åˆ†å¸ƒ
"""

import sys
import os
source_path = '/home/zzp/lab/bubble/bubble-v2/Bubble-fixed2/myPCFG'
sys.path.append(source_path)
# ç¡®ä¿èƒ½å¤Ÿåœ¨source_pathä¸‹è¯»å†™æ–‡ä»¶
os.chdir(source_path)
from pcfg.pcfg import TrainedGrammar, SubGrammar
import json
from helper import random, convert2group
import honeyvault_config as hny_config
from collections import defaultdict, Counter
import math
from datetime import datetime

outdir = "base_ana/"

def pad_y1_PCFG(tg:TrainedGrammar):
    """
    å‘TrainedGrammarçš„Y1éžç»ˆç»“ç¬¦æ·»åŠ ç¼ºå¤±çš„å­—ç¬¦è§„åˆ™
    æ·»åŠ å­—ç¬¦: ", |, }
    é¢‘çŽ‡ä»Ž[100, 30000]èŒƒå›´éšæœºé€‰æ‹©
    """
    # éœ€è¦æ·»åŠ çš„ç¼ºå¤±å­—ç¬¦
    missing_chars = ['"', '|', '}']
    
    # æ£€æŸ¥Y1æ˜¯å¦å­˜åœ¨
    if 'Y1' not in tg.G:
        print("è­¦å‘Š: Y1éžç»ˆç»“ç¬¦ä¸å­˜åœ¨äºŽè¯­æ³•ä¸­")
        return
    
    # èŽ·å–Y1çš„è§„åˆ™å­—å…¸
    y1_rules = tg.G['Y1']
    
    # ä¸ºæ¯ä¸ªç¼ºå¤±å­—ç¬¦æ·»åŠ è§„åˆ™
    added_rules = []
    for char in missing_chars:
        if char not in y1_rules:
            # ä»Ž[100, 30000]èŒƒå›´éšæœºé€‰æ‹©é¢‘çŽ‡
            freq = random.randint(100, 30000)
            y1_rules[char] = freq
            added_rules.append((char, freq))
            print(f"âœ“ æ·»åŠ è§„åˆ™: Y1 -> {char} (é¢‘çŽ‡: {freq})")
        else:
            print(f"Ã— è§„åˆ™å·²å­˜åœ¨: Y1 -> {char} (é¢‘çŽ‡: {y1_rules[char]})")
    
    # é‡æ–°è®¡ç®—__total__
    if '__total__' in y1_rules:
        # æŽ’é™¤__total__é”®ï¼Œè®¡ç®—æ‰€æœ‰è§„åˆ™é¢‘çŽ‡çš„æ€»å’Œ
        total_freq = sum(freq for key, freq in y1_rules.items() if key != '__total__')
        y1_rules['__total__'] = total_freq
        print(f"âœ“ æ›´æ–°Y1æ€»é¢‘çŽ‡: {total_freq}")
    
    print(f"âœ“ æˆåŠŸæ·»åŠ äº† {len(added_rules)} æ¡æ–°è§„åˆ™åˆ°Y1éžç»ˆç»“ç¬¦")

def rule_record(sg):
    # åˆ›å»ºè¯¦ç»†çš„è¯­æ³•è§„åˆ™è®°å½•
    rule_coverage = {}
    with open(outdir + 'dt_sg_rules.txt', 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("SubGrammar å®Œæ•´è¯­æ³•è§„åˆ™è®°å½•\n")
        f.write("=" * 60 + "\n\n")
        
        for nt in sorted(sg.G.keys()):
            if nt != '__total__':
                rules = [k for k in sg.G[nt].keys() if k != '__total__']
                total_freq = sg.G[nt].get('__total__', 0)
                rule_coverage[nt] = {
                    'rule_count': len(rules),
                    'total_frequency': total_freq,
                    'rules': rules[:10]  # æ˜¾ç¤ºå‰10æ¡è§„åˆ™
                }
                
                # å†™å…¥æ–‡ä»¶
                f.write("éžç»ˆç»“ç¬¦: {}\n".format(nt))
                f.write("è§„åˆ™æ•°é‡: {}\n".format(len(rules)))
                f.write("æ€»é¢‘çŽ‡: {}\n".format(total_freq))
                f.write("æ‰€æœ‰è§„åˆ™:\n")
                
                for rule in rules:
                    freq = sg.G[nt].get(rule, 0)
                    prob = freq / total_freq if total_freq > 0 else 0
                    f.write("  {} -> {} (é¢‘çŽ‡: {}, æ¦‚çŽ‡: {:.6f})\n".format(nt, rule, freq, prob))
                f.write("\n" + "-" * 40 + "\n\n")

    print("âœ“ å®Œæ•´è¯­æ³•è§„åˆ™å·²è®°å½•åˆ° {} æ–‡ä»¶ä¸­".format(outdir + 'bg_sg_rules.txt'))

def main():
    print("ðŸš€ é«˜çº§SubGrammaråˆ†æžå¼€å§‹")
    
    # åˆ›å»ºSubGrammar
    tg = TrainedGrammar()
    
    # åœ¨è®°å½•è§„åˆ™ä¹‹å‰ï¼Œå…ˆå¡«å……Y1çš„ç¼ºå¤±è§„åˆ™
    print("=== å¡«å……Y1ç¼ºå¤±è§„åˆ™ ===")
    pad_y1_PCFG(tg)
    print("=== å¡«å……å®Œæˆ ===\n")
    
    rule_record(tg)
    
    outfile = outdir + "basePCFG_grammar_stats.txt"
    with open(outfile, 'w', encoding='utf-8') as f:
        f.write("å¤„ç†æ—¶é—´: {}\n".format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
        f.write("=" * 80 + "\n")
        f.write("Base PCFG Grammarç»Ÿè®¡åˆ†å¸ƒ\n")
        f.write("=" * 80 + "\n")
        
        sg = tg
        # get G['G'] if it exists
        if hasattr(sg, 'G') and 'G' in sg.G:
            f.write("è¯­æ³•è§„åˆ™ (self.G['G']):\n")
            grammar_rules = sg.G['G']
            if grammar_rules:
                # æŒ‰è§„åˆ™åæŽ’åº
                sorted_rules = sorted(grammar_rules.items())
                for rule_name, frequency in sorted_rules:
                    if rule_name != '__total__':
                        total_freq = grammar_rules.get('__total__', 1)
                        probability = frequency / total_freq if total_freq > 0 else 0
                        f.write("  {:<20} | é¢‘çŽ‡: {:<8} | æ¦‚çŽ‡: {:.6f}\n".format(
                            rule_name, frequency, probability))
            else:
                f.write("  (æ— è¯­æ³•è§„åˆ™)\n")
        else:
            f.write("è¯­æ³•è§„åˆ™: (æ— æ³•è®¿é—®)\n")
        
        # get G['T'] if it exists
        if hasattr(sg, 'G') and 'T' in sg.G:
            f.write("è¯­æ³•è§„åˆ™ (self.G['T']):\n")
            grammar_rules = sg.G['T']
            if grammar_rules:
                # æŒ‰è§„åˆ™åæŽ’åº
                sorted_rules = sorted(grammar_rules.items())
                for rule_name, frequency in sorted_rules:
                    if rule_name != '__total__':
                        total_freq = grammar_rules.get('__total__', 1)
                        probability = frequency / total_freq if total_freq > 0 else 0
                        f.write("  {:<20} | é¢‘çŽ‡: {:<8} | æ¦‚çŽ‡: {:.6f}\n".format(
                            rule_name, frequency, probability))
            else:
                f.write("  (æ— è¯­æ³•è§„åˆ™)\n")
        else:
            f.write("è¯­æ³•è§„åˆ™: (æ— æ³•è®¿é—®)\n")

def test_special_pw(pw, tg:TrainedGrammar):
    
    
    original_passwords = ['pint17', 'nmont32', 'jillxsheva', 'bos08051585@boingo.com', 'NASUWT06/87', 'y0us0k']
    sg = SubGrammar(tg)
    sg.update_grammar(*original_passwords)
    # code_g = sg.encode_pw(pw)
    print(f"pw: {pw}")
    pt = sg.max_parse_tree(pw)
    print(f"max parse tree: {pt}")

if __name__ == "__main__":
    # main()
    
    # test bug pws in bubble testset
    tg = TrainedGrammar()
    bug_pws = ['siddique\\']
    for pw in bug_pws:
        test_special_pw(pw, tg)
